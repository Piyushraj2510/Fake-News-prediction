ğŸ“° Fake News Prediction with Logistic Regression  

A simple and efficient machine learning project for detecting fake news articles using Logistic Regression. 

ğŸš€ Features  

- **Text Preprocessing**: Removes noise like stopwords, punctuation, and performs tokenization.  
- **TF-IDF Vectorization**: Converts textual data into meaningful numerical features.  
- **Logistic Regression**: A robust linear model for binary classification.  
- **Model Evaluation**: Provides accuracy, precision, recall, F1-score, and confusion matrix for performance analysis.  

## ğŸ“‚ Project Structure  

```
Fake-News-Prediction/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv             # Training dataset
â”‚   â”œâ”€â”€ test.csv              # Test dataset
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ fake_news_pipeline.ipynb  # End-to-end notebook with preprocessing, training, and evaluation
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py      # Text preprocessing and cleaning functions
â”‚   â”œâ”€â”€ logistic_model.py     # Logistic Regression model implementation
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # Project README
â””â”€â”€ app/
    â”œâ”€â”€ app.py                 # Streamlit app for live predictions
```  

## ğŸ“Š Dataset  

We used the [Fake News Dataset](https://www.kaggle.com/c/fake-news) from Kaggle, which contains labeled news articles with `title`, `text`, and `label` (`1` for fake news, `0` for real news). The dataset is split into training and test sets.  

## âš™ï¸ Installation  

1. Clone the repository:  
   ```bash  
   git clone https://github.com/your-username/fake-news-prediction.git  
   cd fake-news-prediction  
   ```  

2. Install dependencies:  
   ```bash  
   pip install -r requirements.txt  
   ```  

3. Place the dataset files (`train.csv` and `test.csv`) into the `data/` directory.  

## ğŸ§  How It Works  

1. **Text Preprocessing**:  
   - Text is cleaned to remove special characters, numbers, and stopwords.  
   - TF-IDF Vectorizer transforms text into numerical features.  

2. **Model Training**:  
   - Logistic Regression is trained on the TF-IDF features using the `train.csv` dataset.  
   - Hyperparameter tuning with GridSearchCV to optimize performance.  

3. **Model Evaluation**:  
   - The model is evaluated on the `test.csv` dataset.  
   - Performance metrics include accuracy, precision, recall, F1-score, and ROC-AUC.  

## ğŸ–¥ï¸ Usage  

### 1. Run the Notebook  
Execute the step-by-step pipeline in the `notebooks/fake_news_pipeline.ipynb`.  

### 2. Command Line Interface  
Run the training and evaluation pipeline from the terminal:  
```bash  
python src/logistic_model.py --train data/train.csv --test data/test.csv  
```  

### 3. Web App  
Start the Streamlit app for real-time predictions:  
```bash  
cd app  
streamlit run app.py  
```  
Then, open `http://127.0.0.1:8501` in your browser.  

## ğŸ“ˆ Results  

| Metric              | Value   |  
|----------------------|---------|  
| Accuracy            | 91.3%   |  
| Precision           | 90.5%   |  
| Recall              | 91.8%   |  
| F1-Score            | 91.1%   |  

## ğŸ”§ Future Improvements  

- Expand preprocessing techniques to include stemming/lemmatization.  
- Implement additional feature engineering techniques.  
- Deploy the app using Docker for scalability.  

## ğŸ“œ License  

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.  

## ğŸ¤ Contributing  

Contributions are welcome! Please submit a pull request or create an issue for suggestions.  

## ğŸ™Œ Acknowledgments  

- [Kaggle Fake News Dataset](https://www.kaggle.com/c/fake-news)  
- Libraries: Scikit-learn, Pandas, NumPy, Streamlit  

---  

Let me know if you'd like to modify anything or add additional sections!
